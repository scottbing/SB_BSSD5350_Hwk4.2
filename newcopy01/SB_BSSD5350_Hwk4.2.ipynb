{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "congressional-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed for images in notes below\n",
    "from IPython import display  \n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-reaction",
   "metadata": {},
   "source": [
    "# Encoding Words\n",
    "We will process movie reviews that are labeled as having either positive or negative sentiment. This is a binary clasification problem.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amber-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "imdb = tf.keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "altered-latino",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\sbing\\.conda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\sbing\\.conda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "#load the data, but ony the first 10000 most popular words\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "#The warning that comes from this is tensorflow's fault not yours.\n",
    "# Presumably a future version would fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spatial-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the dictionary that allows you to get a word's index\n",
    "word_idxs = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reflected-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to encode reviews as one-hot\n",
    "def encode_review(review, dim):\n",
    "    #create an array of 0s of size passed in\n",
    "    review_vec = np.zeros(dim)\n",
    "    #for each word in review (recall words are numbers)\n",
    "    for word in review:\n",
    "        #set the index for that word number to true\n",
    "        review_vec[word] = 1\n",
    "    #return completed encode\n",
    "    return review_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cardiovascular-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 1., 1., ..., 0., 0., 0.]), array([0., 1., 1., ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of unique words\n",
    "size = len(word_idxs.keys())\n",
    "#encoded training data\n",
    "one_hot_train = []\n",
    "for rev in x_train:\n",
    "    one_hot_train.append(encode_review(set(rev), size))\n",
    "#inspect first 2 vals\n",
    "one_hot_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunset-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#always do the same thing you did to your train to your test data.\n",
    "one_hot_test = []\n",
    "for rev in x_test:\n",
    "    one_hot_test.append(encode_review(set(rev), size))\n",
    "one_hot_test = np.array(one_hot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "detailed-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert ot numpy array\n",
    "one_hot_train = np.array(one_hot_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-draft",
   "metadata": {},
   "source": [
    "## Now we can use the same basic network as last time, but we need more input nodes based on the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "marked-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = one_hot_train.shape[1]\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(128, input_shape=(size,)),\n",
    "  tf.keras.layers.Dense(64),\n",
    "  tf.keras.layers.Dense(32),\n",
    "  #tf.keras.layers.Dropout(.2),  \n",
    "  tf.keras.layers.Dense(16),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1, activation = 'sigmoid') #true=positive, false=negative\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "immune-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recovered-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "49/49 [==============================] - 8s 164ms/step - loss: 0.3696 - accuracy: 0.8373\n",
      "Epoch 2/2\n",
      "49/49 [==============================] - 9s 181ms/step - loss: 0.1802 - accuracy: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d6a65135c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch size will take 64 pieces of my data at a time and run\n",
    "# each batch through the network. If your computer is faster than mine\n",
    "# you can probably bump this number up to 512 instead of 64\n",
    "\n",
    "model.fit(one_hot_train, y_train, epochs=2, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "remarkable-thursday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 8s - loss: 0.3363 - accuracy: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3362812399864197, 0.8664399981498718]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(one_hot_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "significant-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    for p in string.punctuation:\n",
    "        word = word.replace(p, \"\")\n",
    "    return word.lower() #return the word as lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mounted-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review):\n",
    "    \n",
    "    #review cannot have upper case or punctuation\n",
    "    user_review = review\n",
    "    #take each word out of the string\n",
    "    user_review = user_review.split()\n",
    "    clean_review = []\n",
    "    for word in user_review:\n",
    "        clean_review.append(clean_word(word))\n",
    "    #create an empty list to hold the numbers\n",
    "    print(\"clean_review: \", clean_review)\n",
    "    ur = []\n",
    "    for word in clean_review:\n",
    "        #look up the word's index and append it to the list\n",
    "        ur.append(word_idxs[word])\n",
    "    #one-hot the review\n",
    "    oh_ur = np.array(encode_review(set(ur), size))\n",
    "    \n",
    "    #review needs to be in a numpy outer array to be accepted by the model\n",
    "    # needs shape (1,88584), or if there are more reviews it would be\n",
    "    # more than 1 for first dimension\n",
    "\n",
    "    oh_ur = np.array([oh_ur])\n",
    "    predictions = model(oh_ur)\n",
    "    print(predictions)\n",
    "    if predictions > 0.5:\n",
    "        return(\"Favorable\")\n",
    "    else: \n",
    "        return(\"Unfavorable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-blogger",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lonely-healthcare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_review:  ['i', 'did', 'not', 'enjoy', 'that', 'star', 'wars', 'film']\n",
      "tf.Tensor([[0.53391737]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Favorable'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I did not enjoy that Star Wars film.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mineral-fitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_review:  ['miss', 'this', 'movie', 'i', 'do', 'not', 'like', 'it']\n",
      "tf.Tensor([[0.4060053]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Unfavorable'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"miss this movie i do not like it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "defensive-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_review:  ['do', 'not', 'miss', 'this', 'movie', 'i', 'like', 'it']\n",
      "tf.Tensor([[0.4060053]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Unfavorable'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"do not miss this movie i like it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nearby-enforcement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_review:  ['i', 'fell', 'asleep', 'after', 'the', 'first', 'scene']\n",
      "tf.Tensor([[0.39343277]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Unfavorable'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I fell asleep after the first scene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excited-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_review:  ['i', 'liked', 'that', 'the', 'special', 'effects', 'in', 'star', 'wars']\n",
      "tf.Tensor([[0.5122963]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Favorable'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I liked that the special effects in Star Wars.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-narrow",
   "metadata": {},
   "source": [
    "## Homework Due Mon. before 10PM\n",
    "\n",
    "1. Modify the network above to be deeper with more layers. Use the ideas we talked about last time to shrink layer size as you decrease. Add dropout and activations as well. Based on the answer we want and your reading about sigmoid vs softmax, choose the correct activation for the final layer.\n",
    "\n",
    "2. Reconfigure the cell that formats a string into a review and make it a function def that can be called multiple times.\n",
    "\n",
    "3. Make a new cell that passes a few negative and positive sentences that you write, into your new function. Collect all the encoded sentences into one array.\n",
    "\n",
    "4. Make predictions about all of your encoded sentences in your array and print the predictions out to see if they are correct (only one predictions array should need to be created by the model).\n",
    "\n",
    "5. Try out the following two sentences (remember no punctuation or upper case):\n",
    "    - \"miss this movie i do not like it\"\n",
    "    - \"do not miss this movie i like it\"\n",
    "    \n",
    "    Why do you think they yield the same result?\n",
    "\n",
    "_Next time we will continue with words and sentiments and fix the issue  part 5 reveals._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-sailing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-electron",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
